1. How much time did it take to crawl the entire domain?
(set timer)

2. How many unique pages did you find in the entire domain? 
(Uniqueness is established by the URL, not the page's content.)
hashmap of subdomains

3. How many subdomains did you find? Submit the list of subdomains ordered alphabetically 
and the number of unique pages detected in each subdomain. 
The file should be called Subdomains.txt, and its content should be lines containing 
the URL, a comma, a space, and the number.
how many keys do I have in the hashmap set in #2

4. What is the longest page in terms of number of words? 
(Don't count HTML markup as words.)
.getPlainText -> returns a string = longestpage get len(longestpage) 
(hold current yield of longestpage)

5. What are the 500 most common words in this domain? 
(Ignore English stop words, which can be found, for example, at http://www.ranks.nl/stopwords.) Submit the list of common words ordered by frequency (and alphabetically for words with the same frequency) in a file called CommonWords.txt.